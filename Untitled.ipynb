{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "df=pd.read_csv('attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2238\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n"
     ]
    }
   ],
   "source": [
    "print(len(nan_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  5. nan  1.  4.  0.  2.  3.]\n",
      "455\n",
      "6.0    1016\n",
      "1.0     136\n",
      "4.0     134\n",
      "2.0     132\n",
      "0.0     125\n",
      "5.0     125\n",
      "3.0     115\n",
      "Name: neck, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# it means that neck have 6 categories\n",
    "print(df['neck'].unique())\n",
    "nan_neck = df[df['neck'].isnull()]\n",
    "print(len(nan_neck))\n",
    "print(df['neck'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  3.  1.  0.  2.]\n",
      "452\n",
      "2238\n",
      "3.0    1369\n",
      "2.0     148\n",
      "1.0     140\n",
      "0.0     129\n",
      "Name: sleeve_length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# it means sleeve_length has 4 category \n",
    "print(df['sleeve_length'].unique())\n",
    "nan_sleeve_length = df[df['sleeve_length'].isnull()]\n",
    "print(len(nan_sleeve_length))\n",
    "print(len(df['sleeve_length']))\n",
    "print(df['sleeve_length'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  9. nan  8.  6.  1.  3.  7.  2.  0.  5.]\n",
      "447\n",
      "2238\n",
      "9.0    1467\n",
      "6.0      52\n",
      "3.0      46\n",
      "5.0      38\n",
      "1.0      37\n",
      "4.0      37\n",
      "7.0      32\n",
      "8.0      32\n",
      "2.0      29\n",
      "0.0      21\n",
      "Name: pattern, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# it means pattern have 10 category\n",
    "print(df['pattern'].unique())\n",
    "nan_pattern = df[df['pattern'].isnull()]\n",
    "print(len(nan_pattern))\n",
    "print(len(df['pattern']))\n",
    "print(df['pattern'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df[:1900]\n",
    "df[\"neck\"]=df[\"neck\"].replace(np.nan,6.0, regex=True)\n",
    "df[\"sleeve_length\"]=df[\"sleeve_length\"].replace(np.nan,3.0, regex=True)\n",
    "df[\"pattern\"]=df[\"pattern\"].replace(np.nan,9.0, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more then 50% of data is null if we consider all categories/attributes together \n",
    "# replacing nan value by most ocuuring value is suitbale in this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1699 validated image filenames.\n",
      "Found 200 validated image filenames.\n",
      "Found 338 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vibhu\\Anaconda3\\envs\\tensor\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "columns=['neck','sleeve_length','pattern']\n",
    "datagen=ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "# raw class selected as mutilple nd_array output is output from model \n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df[:1700],\n",
    "directory=\"./images\",\n",
    "x_col=\"filename\",\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode='raw',\n",
    "target_size=(100,100))\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1700:1900],\n",
    "directory=\"./images\",\n",
    "x_col=\"filename\",\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode='raw',\n",
    "target_size=(100,100))\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1900:],\n",
    "directory=\"./images\",\n",
    "x_col=\"filename\",\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(100,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vibhu\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vibhu\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "53/53 [==============================] - 136s 3s/step - loss: 16.0780 - accuracy: 0.8842 - val_loss: 15.4371 - val_accuracy: 0.9010\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 136s 3s/step - loss: 15.8279 - accuracy: 0.8896 - val_loss: 15.5227 - val_accuracy: 0.8988\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 152s 3s/step - loss: 15.8236 - accuracy: 0.8854 - val_loss: 15.7559 - val_accuracy: 0.9226\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 151s 3s/step - loss: 15.7476 - accuracy: 0.8938 - val_loss: 15.9627 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 162s 3s/step - loss: 15.7742 - accuracy: 0.8848 - val_loss: 15.6364 - val_accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 162s 3s/step - loss: 15.7026 - accuracy: 0.8914 - val_loss: 16.0057 - val_accuracy: 0.8869\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 159s 3s/step - loss: 15.8288 - accuracy: 0.8878 - val_loss: 15.7244 - val_accuracy: 0.9107\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 161s 3s/step - loss: 15.6895 - accuracy: 0.8830 - val_loss: 16.0043 - val_accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 160s 3s/step - loss: 15.8550 - accuracy: 0.8944 - val_loss: 15.8317 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 163s 3s/step - loss: 15.6103 - accuracy: 0.8872 - val_loss: 16.0471 - val_accuracy: 0.9048\n",
      "338/338 [==============================] - 14s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")\n",
    "model.save_weights(\"model.h5\")\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "predictions = pred.astype(int)\n",
    "columns=['neck','sleeve_length','pattern']\n",
    "#columns should be the same order of y_col\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"Filenames\"]=test_generator.filenames\n",
    "ordered_cols=[\"Filenames\"]+columns\n",
    "results=results[ordered_cols]#To get the same column order\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
